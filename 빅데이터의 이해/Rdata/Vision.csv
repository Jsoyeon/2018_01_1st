한국미래기술교육연구원은?오는?5월?17일(목)?서울?여의도?전경련회관?로즈홀에서?'[Intensive?Course]?컴퓨터비전?기반의?영상인식?알고리즘과?산업별?구현기술?전문가과정'을?개최?한다고?밝혔다.

"컴퓨터에?인간의?시각적인?부분을?재현하는?연구?분야인?컴퓨터비전은?인간이?눈을?통해?정보를?얻는?것처럼?입력?영상에서?의미?있는?정보를?추출해내는?인공지능의?한?분야로써?최근?딥?러닝등이?접목되면서?자율주행차,?산업용?로봇,?의료?영상?진단기술,?스마트?홈,?보안?및?영상감시?산업?등?각종?산업에서?가장?괄목할만한?성과를?나타내고?있다.?"

"특히,?가속도가?붙기?시작한?빅데이터의?발전으로?인하여?컴퓨터비전?기반의?영상인식?기술은?객체?검출,?인식,?매칭기술?등을?통하여?증강현실,?스마트팩토리(머신비전),?자율주행차,?의료분야와?같은?핵심?산업에?더욱?활용범위가?넓어지고?있다.?"

"최적의?알고리즘으로?구현된?이미지/영상?정보는?이렇게?산업마다?실제로?응용되고?있는?가운데,?모바일?및?웹까지?ICT?기업들?간의?시장경쟁에서?가장?중요한?기술력이?될?것으로?평가되고?있다."

"금번,?전문가?과정은?△'[의료]?딥러닝과?빅데이터를?이용한?의료분야?영상인식?알고리즘?개발과?구현기술'?△'[자율주행차]?딥러닝을?이용한?자율차분야?영상인식?알고리즘?기술?및?서비스?적용방안안'?△'[증강현실]?인터랙티브?증강현실?어플리케이션을?위한?컴퓨터?비전?기술'?"

△'[스마트?팩토리]?딥러닝과?빅데이터?기반의?최적의?머신비젼?알고리즘?개발과?구현기술'?등?컴퓨터비전?기반의?영상인식?기술이?가장?활발하게?적용되고?있는?산업?분야별로?다루어질?예정이다.

"연구원?관계자는?""금번?전문가과정을?통하여?그동안?딥?러닝에?의해서?구현되기?시작한?컴퓨터?비전?기반의?인공지능?영상인식?알고리즘?기술과?관련하여?심도있는?논의를?함으로써?향후?이?분야?기술의?정확성을?더욱?높이며,?검증을?통해?신뢰성을?높일?수?있는?방안과?기술적/사업적?노하우?를?공유함과?더불어?관련업계?종사자에게?수준?높은?최신?기술?정보는?물론,?미래?비즈니스?기회?선점이?가능한?시장?정보까지?제공할?계획이다.""라고?밝혔다."


동물의 이동을 연구하는데 그동안 GPS나 무선 장비가 주로 활용됐다. 동물의 목에 GPS 단말기를 착용하는 방식이었다.

하지만 최근 영국 글래스고대학과 산타페연구소의 과학자들은 드론과 컴퓨터 비전시스템(카메라)을 활용해 무리지어 이동하는 동물의 움직임을?연구하는 시도를 했다. 무리를 지어 이동하는 순록 등 동물의?움직임을 드론과 컴퓨터 비전 시스템을 활용해 장시간 관찰했다. 이들 연구팀은 연구 결과를 영국 왕립학회에서 발행하는 저널인?'Philosophical Transaction of the Royal Society B.'에 기고했다.

연구팀에 따르면 순록 등 무리를 지어 움직이는 동물들은 결코 순응주의자가 아닌 것으로 나타났다. 자신의 앞에 있는 동족만을 무작정 따라가지는 않는다는 사실이다.?연구팀은 캐나다 본토와 빅토리아섬을 이동하는 순록의 무리를 장기간?관찰했다. 드론과 컴퓨터 비전 시스템을 이용해 무리에 섞여 있는 개체의 이동과 다른 순록들과의 상호작용을 살폈다. 그동안 GPS 장비를 이용한 동물들의 관찰은 특정 개체의 이동만을 파악했지 그들 개체 상호간에 어떤 사회적인 영향이 있는지는?살피지 못했다.

이번 연구를 주도한 산타페연구소의 환경과학자인 ‘앤드류 버달(Andrew Berdahl)’은 “드론과 컴퓨터비전 등 새로운 테크놀로지를 이용해 전체 그룹에 속해 있는 동물들의 개별적인 데이터를 수집하는 것은 매우 흥분되는 일이었다”고 말했다.?연구팀은 무리를 지어 움직이는 동물들의 행동이 유사할 것이라는 전통적인 가정에 의문을 제기했다.

각 개체들은 성별과 나이에 따라 사회성 측면에서 다양한 변이를 보이고 있다는 설명이다. 예를 들어 송아지는 고도로 사회적인데 반해 성인 황소들은 보다 독립적으로 행동한다는 것. 순록의 경우도 집단 이주를 하는 과정에서 옆에 있는 동료보다는 앞서 가는 동료들로부터 영향을 받는 것으로 나타났다. 이는 순록의 무리들이 비대칭적인 형태로 이동한다는 에스키모족 ‘이누이트(Innuit)’의 지식과도 합치된다는 지적이다. 이누이트족은 리더를 형성하는?순록 무리의?하위단위(subset)에서 집단 이주의 경로를 주도적으로?이끈다는 생각을 갖고 있다.

"연구자들은 “궁극적으로 사회적인 역동성이 전체적인 수준에서 의미를 갖기 때문에 동물들의 집단 행동의 연구가 중요하다""고 지적했다."


"여러 기업들에서 AI에 대한 투자를 진행하고 있다. 투자까지 안 가더라도, 최소한 알아보고는 있다. 인공지능이라는 것을 통해 운영 효율을 얼마나 높일 수 있고, 고객들을 얼마나 만족시킬 수 있는지 재보는 것이다. 그러나 기계와 소통하는 건, 말 그대로 ‘기계적’일뿐이라는 것에 일반적인 사람들은 한계를 느끼는 게 사실이다. 처음 몇 번이야 신기하긴 하지만, 그 이상의 속 시원한 느낌은 주지 못한다는 것이다."

"아직까지 인간과 기계의 소통은 완전하지 않다. 기계나 인간이나, 서로에게 이야기하는 법을 제대로 알고 있지 못하다. 그런 소통의 어긋남 사이에서 비효율이 발생하고, 이는 일반적인 최종 사용자들에게 있어 ‘짜증’ 정도의 감정으로 다가간다. 그리고 대화 상대인 기계가 그러한 감정을 전혀 이해하지 못하고 입력된 답만 똑같이 내뱉을 때, 인간은 더 대화를 진행할 필요를 못 느낀다. 공감 결여, 그것이 인간과 기계 사이의 대화가 갖는 최종 도착지다."

"인간과 기계 사이의 상호작용을 원활히 하기 위해서는 인공지능이 좀 더 인간스러워져야 한다. 그러려면 인간의 감정적인 상태와 변화를 이해하고, 그에 맞는 대응을 할 줄 알아야 한다. 그 외 옵션이라면 인간이 아무런 감정 없는 기계처럼 변해야 하는 것 정도가 있을 것이다."

인공 감성 지능의 스펙트럼
"메리암 웹스터 사전에 의하면 ‘공감(empathy)’의 정의는 이것이다. “다른 사람의 과거나 현재의 생각, 경험, 감정을 노골적인 설명이나 명백한 소통 없이 대신해 경험하고 민감하게 반응하며, 알아채고 이해하는 행위 혹은 그렇게 할 수 있는 능력.” 이 정의에 따라 인공지능에 공감 능력을 부여하려면, 결국 기계가 감정을 경험할 수 있어야 한다. 그리고 감정을 경험하려면 감정을 인지하고 이해할 수 있어야 한다.?"

꿈같은 이야기만은 아니다. 비영리 연구 단체인 SRI 인터내셔널(SRI International) 등은 이미 인공지능이 감정을 인지하게 하는 데까지는 성공했다. 다만 그것을 이해시키는 것은 아직 어렵다고 한다. 사실 사람만 해도 감정을 경험하고 해석하는 것이 전부 제각각이니 말이다. 상대방 감정에 대한 이해는 규칙적으로 딱딱 정해진 게 아닌 분야.

“먼저 사람조차도 감정이라는 것을 온전히 이해하고 있지 못합니다. 컴퓨터와 감정을 연결시키기에는 아직 한참 멀었고요. 인공지능의 공감은 대단히 요원한 일이라고 생각합니다.” SRI 인터내셔널의 정보 컴퓨터 서비스 부문 회장인 빌 마크(Bill Mark)의 설명이다. 참고로 SRI 인터내셔널의 정보 컴퓨터 서비스부는 애플이 시리가 태어난 곳이다.?

"“사람마다 감정에 대한 반응도 달라요. 누구는 기뻐서 울고, 누구는 슬퍼서 울죠. 짜증날 때 미소를 짓는 사람이 얼마나 많은지 사람들은 잘 모를 걸요? 미소를 짓는다는 건 마음이 기쁘다는 것, 이라는 단순한 접근으로는 감정을 이해할 수도 없고, 사람과 공감할 수도 없습니다.”"

"다만 감정을 인지하는 것 자체는 한결 쉬운 문제다. 왜냐하면 감정과 관련된 수많은 데이터를 머신 러닝 시스템에 주입하면, 기기가 특정 감정에 대한 패턴을 읽어낼 수 있기 때문이다. 다양한 텍스트나 음성, 스피치 파일을 통해서도 감정 인지를 학습시키는 것도 가능하고 제스처와 표정도 풍부한 데이터가 되어 준다. 사람과 마찬가지로 기기도 충분한 학습을 통해 감정을 인지하는 데까지는 도달할 수 있다."

"그러나 인지와 이해가 전혀 다른 것이라는 게 문제다. 예를 들어 컴퓨터 비전은 이제 고양이와 개를 높은 확률로 구분할 줄 안다. 그러나 아직은 고양이와 개가 가지고 있는 행동적 특성에 대해서는 이해하지 못한다. 또한 사람이 애완동물로서 고양이나 개를 키울 수 있다든가, 동물과 사람이 서로 교감(좋아하거나 싫어하거나)할 수 있다는 것도 컴퓨터에겐 이해 불가능의 영역이다.?"

"한 단계 더 나아가, 이해를 한다손 치더라도 그것이 ‘공감’은 아니다. 인지와 이해가 다른 것만큼 이해와 공감도 다른 문제다. 예를 들어 여기 세 명의 사람이 있다고 하자. 한 사람은 매우 화가 나 있는 상태다. 그리고 나머지 둘은 그 사람이 화를 내고 있다는 걸 이해하고 있다. 왜 화가 났는지도 알고 있다. 그러나 공감까지 하지는 않는 것도 가능하다. 심지어 그 사람이 화를 내든 말든 전혀 신경 쓰지 않거나, 그 상황이 재미있다고 느낄 수도 있다."

"최근 아마존의 알렉사가 일부 사용자들을 굉장히 놀라게 한 적이 있다. 아무런 맥락이나 이유 없이 혼자서 크게 웃었기 때문이다. 기계가 갑자기 혼자 웃음을 터트리니 사람들은 놀랄 수밖에 없었다. 조사를 해보니 알렉사에 ‘알렉사, 웃어’라는 음성 명령이 입력되어 있었다. 누군가 어디선가 그와 비슷한 말을 한 것을 알렉사가 들어버린 것이었다. 그러나 해당 알렉사 주변에서는 그런 말을 한 사람이 아무도 없었다. 알렉사가 뭘 듣고 웃었는지는 확실하지 않지만, 아무튼 뭔가 오류로 인한 명령이 입력된 후에 행동을 한 것이므로, 해당 사건은 그렇게 끝이 났다. 하지만 알렉사가 혼자서 감정을 가지고, 스스로 판단해서 웃었다고 상상해보라. 그것도 주인의 우울한 감정을 보고 ‘우습다’고 느껴서 웃은 것이라면 그 주인의 기분이 어땠을까?"

“시리 혹은 시리와 유사한 시스템들은 단발적인 반응을 하는 데에 있어서 좋은 성능을 보입니다. 뭔가 질문을 하면 그에 대한 답을 찾아내준다는 말이죠. 하지만 은행 및 금융 관련 업무를 처리하거나 쇼핑을 하거나 건강 상담을 할 때는 질문 한 번에 답 한 번으로 대화가 끝나지 않습니다. 길고 긴 대화가 이어지죠. 원하는 것과 필요한 것을 단 한 번에 한 문장으로 다 이어붙일 수 없기 때문입니다. 또한 그에 대한 답을 제공할 때도 마찬가지죠. 그래서 한 번에 하나씩 문제를 해결해가며 대화를 길게 하는 게 보통입니다. 그리고 이런 식의 대화에는 감정적인 교류가 반드시 있어야 합니다. 무미건조하게 스무고개를 하며 대출 상담을 받고 건강 검진을 받는 건 의외로 불가능합니다.” 마크의 설명이다.

개인화와 보편화
"사람의 감정 처리 습관과 방식이 전부 다르기 때문에 당장 나와 대면하고 있는 단 한 사람의 감정을 이해하고 공감하는 것도 충분히 어려운 일이긴 하지만, 그래도 자주 얼굴을 보면 볼수록 나아진다. 기계도 마찬가지다. 인간의 보편적인 감정 상태와 반응을 이해하긴 힘들지만, 그래도 자주 상호작용을 하는 사람의 감정을 보다 더 쉽게 이해할 수 있다.?"

"“어떤 사람이 가상 비서와 꾸준히 상호작용을 했다고 합시다. 그러면 그 가상 비서는 다른 사람은 몰라도 그 특정 사용자 한 사람에 대해서만큼은 꽤나 정확한 반응과 데이터 모델링을 할 수 있습니다.” 마크의 설명이다. “그렇다면 이런 개인화 과정을 충분히 거치면 보편화도 할 수 있을까요? 저는 ‘그렇다’고 봅니다만, 우리가 아는 ‘보편화’보다는 제한적일 것이라고 예상합니다.”"

"사람마다 제각각인 특성을 고려하면 ‘보편화’가 훨씬 더 어려운 작업일 것이라는 건 쉽게 이해가 된다. 각자가 선천적으로 가지고 태어난 성향과, 자라오면서 접하는 모든 요인들과 교육적 토양, 문화 등의 변수가 겹쳐져 우린 단 한 사람도 동일하지 않다. 그러니 기계가 사람에 대한 보편성을 익힌다는 것이 얼마나 어려울지 짐작이 가능하다. 회사들이 기다리고 있는 ‘모든 고객을 상대하는 인공지능’을 만든다는 것이 얼마나 어려운 일일까 역시 상상이 가능하다."

"하지만 다른 의견도 있다. 글로벌 컨설턴팅 업체인 EY에서 AI 분야를 담당하고 있는 케이스 스트라이어(Keith Strier)에 따르면 “감정을 인지하고 이해하는 건 결국 패턴 인지의 문제”라고 정리한다. “사람에게나 기계나, 이는 마찬가지입니다. 우린 무수한 사례를 통해 패턴을 익힘으로써 감정을 인지하고 이해합니다.” 또한 스트라이어는 “도소매 산업에서는 매장 내 쇼핑 경험을 풍부하게 하고 개인화 하기 위한 개념증명이 곧 완성될 예정”이라고 덧붙인다.?"

"“머신 러닝과 컴퓨터 비전, 그리고 다른 기타 도구들을 혼합함으로써 기계가 사람의 감정을 읽어내고 이해할 수 있게 할 수 있습니다. 그리고 그런 정보들을 가지고 인간과 상호작용할 수 있게 만드는 것도 가능합니다.”"

"특히 엔터테인먼트 산업에서 이러한 감정 관련 정보가 풍부하게 발생할 수 있을 것이라고 스트라이어는 예상한다. “예를 들어 영화 관람객의 감정적인 반응을 모니터링 하면서 영화의 장면이나 음악, 등장인물의 행동을 매칭시켜 상호작용하는 법을 익히게 할 수도 있습니다. 엔터테인먼트 산업만큼 인간의 감정을 잘 조정할 수 있는 곳도 없지요. 사람을 무섭게도 하고, 재미있게도 하며 슬프게도 하니까요.”"

"결국 스트라이어는 “이렇든 저렇든 결국 수학의 문제로 귀결된다”고 해석한다. “감정을 이해하고, 그 이해에 따라 적절히 행동하게 하는 건 전부 수학으로 해결할 수 있다고 저는 생각합니다. 아마 인공지능과 감정에 대한 수학적 이론을 다룬 논문이 계속해서 등장할 것입니다. 단순 예측이 아니라 그런 방식의 연구가 이미 많이 진행되고 있기에 하는 말입니다.”"

"개인화, 정말 개인화답게"
"보편화야 그렇다 치고, 개인화는 특히 마케터들 사이에서 크게 각광받고 있는 기술이다. 마케터들은 이미 오래전부터 각종 연구 및 통계 자료를 바탕으로 최대한 개인적인 서비스를 많은 이들에게 제공하기 위해 애써왔다. 개인화만 이뤄진다면 충성 고객을 만들 수 있기 때문이다. 현대의 마케터들은 기존의 통계 자료에 더해 GPS와 소프트웨어 사용량 분석 자료, 소비자들의 맥락 정보 등까지 활용해 개인화에 힘쓰고 있다."

"“감정과 관련된 정보를 추가하면 개인화가 더 강력해집니다. 내가 누구인지, 뭐하는 사람인지, 내 프로파일 상의 정체가 무엇인지에 기반을 둔 개인화에 더해 감정적인 상태까지 덧붙게 되면 궁극의 개인화가 완성될 것입니다. 사실 사람은 프로필에 나온 것처럼 항상 일정하게 반응하지 않기 때문이죠. 매순간 감정적으로만 행동하지는 않더라도, 일정부분 감정이라는 변수에 따라 판단을 내리고 행동할 때가 많죠. 인공지능에 감정적인 요소를 더하는 건 개인화의 측면에서 큰 혁신을 일으킬 것입니다.”"

"하지만 스트라이어는 순수 기술적 발전도 좋지만 ‘실제 사용 사례’를 고려하는 걸 잊지 말아야 한다고 강조한다. “인공지능이나 감정 모두 단 한 개의 기술이나 현상을 말하는 게 아닙니다. 통합적이고 복합적인 것을 아울러 지칭하는 것이죠. 그러므로 인공지능에 감정을 더하거나, 인공 감성을 만드는 것 역시 단 한 개의 기술이나 공식만을 말하는 게 아닐 겁니다. 즉, 어떤 현장과 상황에서, 어떤 기술을 어떤 식으로 도입하느냐의 문제로 귀결될 것으로 예상합니다. 어떤 상황에선 감정을 인지하는 것만으로도 충분하겠고, 어떤 곳에서는 공감까지 가야만 하겠죠.”"

"그러면서 한 가지 예를 든다. “현재 한 국립은행에서 스마트 ATM이라는 걸 검토하고 있습니다. 이 기기는 ATM 방문자의 표정을 읽고, 감정을 인지할 줄 압니다. 그들의 목소리 톤을 읽고, 몸짓을 해석하고, 사용하는 단어나 눈의 움직임 등도 포착해 감정 상태를 최대한 가깝게 파악한다고 합니다. 그런데 말입니다, ATM이 사람 감정을 잘 읽어내야 하는 이유가 뭐냐는 거죠. 그 다음은요?” 결국 인공 감정이나 인공지능의 공감 기술에 대한 사용 사례 고민이 먼저가 아니겠느냐는 지적이다. “기술은 필요에 의해 나타나는 건데, 기술이 먼저 생기고 필요를 거기에 끼워 맞추는 게 자연스럽냐는 것입니다.”"

"인공지능이 감정을 느낄 수 있느냐 없느냐, 그럴 필요가 있느냐 없느냐는 아직도 논란의 대상이다. 하지만 인공지능에게 감정을 부여하는 방법을 연구함으로써 인간의 감정에 대한 보다 더 깊은 이해와 감정적 대응과 기계적 대응에 대한 시장의 필요성을 고민할 수 있다는 것이 현재까지의 성과임은 분명하다.?"
